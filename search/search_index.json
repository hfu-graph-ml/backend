{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Backend Tech stack FastAPI is used for HTTP routing Development The following tools are needed: Python > 3.8 Pip Make Initialization These steps are required to setup the development enviroment: git clone git@github.com:hfu-graph-ml/backend.git make init Activation On Linux the VENV activation is straight forward: source .venv/Scripts/activate There are slight differences between CMD and PowerShell in Windows (as always). It is recommended to use PS Core, as it is more modern and resembles a Linux shell more closely (cd, rm, ...) # On CMD .venv/Scripts/activate.bat # On PS (Core) .venv/Scripts/Activate.ps1 Install dependencies and run server To install dependencies run: make install After that we can run the server via make run . Adding new dependencies First make sure you activated the VENV. Then run: pip install <package> pip freeze > requirements.txt","title":"Backend"},{"location":"#backend","text":"","title":"Backend"},{"location":"#tech-stack","text":"FastAPI is used for HTTP routing","title":"Tech stack"},{"location":"#development","text":"The following tools are needed: Python > 3.8 Pip Make","title":"Development"},{"location":"#initialization","text":"These steps are required to setup the development enviroment: git clone git@github.com:hfu-graph-ml/backend.git make init","title":"Initialization"},{"location":"#activation","text":"On Linux the VENV activation is straight forward: source .venv/Scripts/activate There are slight differences between CMD and PowerShell in Windows (as always). It is recommended to use PS Core, as it is more modern and resembles a Linux shell more closely (cd, rm, ...) # On CMD .venv/Scripts/activate.bat # On PS (Core) .venv/Scripts/Activate.ps1","title":"Activation"},{"location":"#install-dependencies-and-run-server","text":"To install dependencies run: make install After that we can run the server via make run .","title":"Install dependencies and run server"},{"location":"#adding-new-dependencies","text":"First make sure you activated the VENV. Then run: pip install <package> pip freeze > requirements.txt","title":"Adding new dependencies"},{"location":"graphs/completion/","text":"","title":"Completion"},{"location":"graphs/test/","text":"","title":"Test"},{"location":"graphs/train/","text":"","title":"Train"},{"location":"graphs/callbacks/callbacks/","text":"ConfigLoggerCallback Bases: BaseCallback Callback for printing the configuration file used to train the model to the TensorBoard log. Parameters: Name Type Description Default config Configuration as dict. config Source code in backend/graphs/callbacks/callbacks.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class ConfigLoggerCallback ( BaseCallback ): ''' Callback for printing the configuration file used to train the model to the TensorBoard log. Args: config: Configuration as dict. ''' def __init__ ( self , config = config ): super ( ConfigLoggerCallback , self ) . __init__ ( verbose = 0 ) self . config = config def _on_training_start ( self ) -> bool : # Save reference to tensorboard formatter object # note: the failure case (not formatter found) is not handled here, should be done with try/except. self . tb_formatter = next ( formatter for formatter in self . logger . output_formats if isinstance ( formatter , TensorBoardOutputFormat )) self . tb_formatter . writer . add_text ( \"info/config\" , str ( json . dumps ( self . config , indent = 2 ) ) . replace ( ' ' , '&nbsp;&nbsp;&nbsp;&nbsp;' ) . replace ( ' \\n ' , ' \\n ' ), self . num_timesteps ) self . tb_formatter . writer . flush () return True def _on_step ( self ) -> bool : return True LogBestGraph Bases: BaseCallback Callback for logging and keeping track of the highest and lowest mood scores of valid graphs the model generates to the TensorBoard log. The best valid graph will also be visualized as figure. Parameters: Name Type Description Default check_freq int Frequency of steps in which to log a new value. Defaults to number of steps per epoch. config['training']['steps_per_epoch'] Source code in backend/graphs/callbacks/callbacks.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 class LogBestGraph ( BaseCallback ): ''' Callback for logging and keeping track of the highest and lowest mood scores of valid graphs the model generates to the TensorBoard log. The best valid graph will also be visualized as figure. Args: check_freq: Frequency of steps in which to log a new value. Defaults to number of steps per epoch. ''' def __init__ ( self , check_freq : int = config [ \"training\" ][ \"steps_per_epoch\" ]): super ( LogBestGraph , self ) . __init__ () self . check_freq = check_freq self . highest_mood_score = None self . lowest_mood_score = None self . got_new_highest_mood_score = False self . highest_mood_score_graph = None self . tb_formatter = None def _on_training_start ( self ) -> bool : self . tb_formatter = next ( formatter for formatter in self . logger . output_formats if isinstance ( formatter , TensorBoardOutputFormat )) return True def _on_step ( self ) -> bool : mood_scores = [ x [ \"mood_score\" ] for x in self . locals [ \"infos\" ]] highest_mood_score_index = np . argmax ( np . nan_to_num ( mood_scores )) highest_mood_score = mood_scores [ highest_mood_score_index ] if not isnan ( highest_mood_score ) and ( self . highest_mood_score == None or highest_mood_score > self . highest_mood_score ): self . highest_mood_score = highest_mood_score self . highest_mood_score_graph = copy . deepcopy ( self . locals [ \"infos\" ][ highest_mood_score_index ][ \"graph\" ]) self . got_new_highest_mood_score = True lowest_mood_score_index = np . argmin ( np . nan_to_num ( mood_scores , nan = 1000 )) lowest_mood_score = mood_scores [ lowest_mood_score_index ] if not isnan ( lowest_mood_score ) and ( self . lowest_mood_score == None or lowest_mood_score < self . lowest_mood_score ): self . lowest_mood_score = lowest_mood_score if self . n_calls % self . check_freq == 0 : self . logger . record ( 'rollout/highest_mood_score' , self . highest_mood_score ) self . logger . record ( 'rollout/lowest_mood_score' , self . lowest_mood_score ) if self . got_new_highest_mood_score : fig = draw_graph ( self . highest_mood_score_graph , show_graph = False ) self . logger . record ( \"graphs/highest_mood_score_graph\" , Figure ( fig , close = True ), exclude = ( \"stdout\" , \"log\" , \"json\" , \"csv\" )) graph_edge_list_string = \"\" for edge in edgelist . generate_edgelist ( self . highest_mood_score_graph , delimiter = \", \" , data = False ): graph_edge_list_string = graph_edge_list_string + f \"( { edge } ),&nbsp;\" graph_edge_list_string = graph_edge_list_string [: - 7 ] self . tb_formatter . writer . add_text ( \"graphs/highest_mood_score_graph\" , graph_edge_list_string , self . num_timesteps ) self . tb_formatter . writer . flush () self . got_new_highest_mood_score = False return True LogMoodScores Bases: BaseCallback Callback for logging the mean mood score of valid graphs the model generates to the TensorBoard log. NaN if the model didn't generate any valid graphs. Parameters: Name Type Description Default check_freq int Frequency of steps in which to log a new value. Defaults to number of steps per epoch. config['training']['steps_per_epoch'] Source code in backend/graphs/callbacks/callbacks.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 class LogMoodScores ( BaseCallback ): ''' Callback for logging the mean mood score of valid graphs the model generates to the TensorBoard log. NaN if the model didn't generate any valid graphs. Args: check_freq: Frequency of steps in which to log a new value. Defaults to number of steps per epoch. ''' def __init__ ( self , check_freq : int = config [ \"training\" ][ \"steps_per_epoch\" ]): super ( LogMoodScores , self ) . __init__ () self . check_freq = check_freq self . mood_scores = [] def _on_step ( self ) -> bool : mood_scores = [ x [ \"mood_score\" ] for x in self . locals [ \"infos\" ]] self . mood_scores . append ( mood_scores ) if self . n_calls % self . check_freq == 0 : mean_mood_score = np . nanmean ( self . mood_scores ) self . logger . record ( 'rollout/mean_mood_score' , mean_mood_score ) self . mood_scores = [] return True LogValidActions Bases: BaseCallback Callback for logging the ratio of valid actions the model takes to the TensorBoard log. Parameters: Name Type Description Default check_freq int Frequency of steps in which to log a new value. Defaults to number of steps per epoch. config['training']['steps_per_epoch'] Source code in backend/graphs/callbacks/callbacks.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class LogValidActions ( BaseCallback ): ''' Callback for logging the ratio of valid actions the model takes to the TensorBoard log. Args: check_freq: Frequency of steps in which to log a new value. Defaults to number of steps per epoch. ''' def __init__ ( self , check_freq : int = config [ \"training\" ][ \"steps_per_epoch\" ]): super ( LogValidActions , self ) . __init__ () self . check_freq = check_freq self . valid_actions = [] def _on_step ( self ) -> bool : self . valid_actions . append ([ x [ \"action_valid\" ] for x in self . locals [ \"infos\" ]]) if self . n_calls % self . check_freq == 0 : _ , counts = np . unique ( self . valid_actions , return_counts = True ) valid_action_ratio = counts [ 1 ] / ( counts [ 0 ] + counts [ 1 ]) self . logger . record ( 'rollout/valid_action_ratio' , valid_action_ratio ) self . valid_actions = [] return True LogValidGraphs Bases: BaseCallback Callback for logging the ratio of valid graphs the model generates to the TensorBoard log. Parameters: Name Type Description Default check_freq int Frequency of steps in which to log a new value. Defaults to number of steps per epoch. config['training']['steps_per_epoch'] Source code in backend/graphs/callbacks/callbacks.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 class LogValidGraphs ( BaseCallback ): ''' Callback for logging the ratio of valid graphs the model generates to the TensorBoard log. Args: check_freq: Frequency of steps in which to log a new value. Defaults to number of steps per epoch. ''' def __init__ ( self , check_freq : int = config [ \"training\" ][ \"steps_per_epoch\" ]): super ( LogValidGraphs , self ) . __init__ () self . check_freq = check_freq self . valid_graphs = [] def _on_step ( self ) -> bool : self . valid_graphs . append ([ x [ \"graph_valid\" ] for x in self . locals [ \"infos\" ]]) if self . n_calls % self . check_freq == 0 : u , c = np . unique ( self . valid_graphs , return_counts = True ) counts = dict ( zip ( u , c )) n_valid = counts [ 1 ] if 1 in counts . keys () else 0 n_invalid = counts [ 0 ] if 0 in counts . keys () else 0 valid_graph_ratio = n_valid / ( n_invalid + n_valid ) self . logger . record ( 'rollout/valid_graph_ratio' , valid_graph_ratio ) self . valid_graphs = [] return True SaveOnBestTrainingRewardCallback Bases: BaseCallback Callback for saving a model (the check is done every check_freq steps) based on the training reward. Parameters: Name Type Description Default log_dir str Path to the folder where the model will be saved. It must contains the file created by the Monitor wrapper. required check_freq int Frequency of steps in which to check if a better model can be saved. Defaults to number of steps per epoch. config['training']['steps_per_epoch'] verbose int Verbosity level. 1 Source code in backend/graphs/callbacks/callbacks.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class SaveOnBestTrainingRewardCallback ( BaseCallback ): ''' Callback for saving a model (the check is done every ``check_freq`` steps) based on the training reward. Args: log_dir: Path to the folder where the model will be saved. It must contains the file created by the ``Monitor`` wrapper. check_freq: Frequency of steps in which to check if a better model can be saved. Defaults to number of steps per epoch. verbose: Verbosity level. ''' def __init__ ( self , log_dir : str , check_freq : int = config [ \"training\" ][ \"steps_per_epoch\" ], verbose : int = 1 ): super ( SaveOnBestTrainingRewardCallback , self ) . __init__ ( verbose ) self . check_freq = check_freq self . log_dir = log_dir self . save_path = os . path . join ( log_dir , 'best_model' ) self . best_mean_reward = - np . inf def _init_callback ( self ) -> None : # Create folder if needed if self . save_path is not None : os . makedirs ( self . save_path , exist_ok = True ) def _on_step ( self ) -> bool : if self . n_calls % self . check_freq == 0 : # Retrieve training reward x , y = ts2xy ( load_results ( self . log_dir ), 'timesteps' ) if len ( x ) > 0 : # Mean training reward over the last 100 episodes mean_reward = np . mean ( y [ - 100 :]) if self . verbose > 0 : print ( f \"Num timesteps: { self . num_timesteps } \" ) print ( f \"Best mean reward: { self . best_mean_reward : .2f } - Last mean reward per episode: { mean_reward : .2f } \" ) # New best model, you could save the agent here if mean_reward > self . best_mean_reward : self . best_mean_reward = mean_reward # Example for saving best model if self . verbose > 0 : print ( f \"Saving new best model to { self . save_path } \" ) self . model . save ( self . save_path ) return True","title":"Callbacks"},{"location":"graphs/callbacks/callbacks/#backend.graphs.callbacks.callbacks.ConfigLoggerCallback","text":"Bases: BaseCallback Callback for printing the configuration file used to train the model to the TensorBoard log. Parameters: Name Type Description Default config Configuration as dict. config Source code in backend/graphs/callbacks/callbacks.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 class ConfigLoggerCallback ( BaseCallback ): ''' Callback for printing the configuration file used to train the model to the TensorBoard log. Args: config: Configuration as dict. ''' def __init__ ( self , config = config ): super ( ConfigLoggerCallback , self ) . __init__ ( verbose = 0 ) self . config = config def _on_training_start ( self ) -> bool : # Save reference to tensorboard formatter object # note: the failure case (not formatter found) is not handled here, should be done with try/except. self . tb_formatter = next ( formatter for formatter in self . logger . output_formats if isinstance ( formatter , TensorBoardOutputFormat )) self . tb_formatter . writer . add_text ( \"info/config\" , str ( json . dumps ( self . config , indent = 2 ) ) . replace ( ' ' , '&nbsp;&nbsp;&nbsp;&nbsp;' ) . replace ( ' \\n ' , ' \\n ' ), self . num_timesteps ) self . tb_formatter . writer . flush () return True def _on_step ( self ) -> bool : return True","title":"ConfigLoggerCallback"},{"location":"graphs/callbacks/callbacks/#backend.graphs.callbacks.callbacks.LogBestGraph","text":"Bases: BaseCallback Callback for logging and keeping track of the highest and lowest mood scores of valid graphs the model generates to the TensorBoard log. The best valid graph will also be visualized as figure. Parameters: Name Type Description Default check_freq int Frequency of steps in which to log a new value. Defaults to number of steps per epoch. config['training']['steps_per_epoch'] Source code in backend/graphs/callbacks/callbacks.py 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 class LogBestGraph ( BaseCallback ): ''' Callback for logging and keeping track of the highest and lowest mood scores of valid graphs the model generates to the TensorBoard log. The best valid graph will also be visualized as figure. Args: check_freq: Frequency of steps in which to log a new value. Defaults to number of steps per epoch. ''' def __init__ ( self , check_freq : int = config [ \"training\" ][ \"steps_per_epoch\" ]): super ( LogBestGraph , self ) . __init__ () self . check_freq = check_freq self . highest_mood_score = None self . lowest_mood_score = None self . got_new_highest_mood_score = False self . highest_mood_score_graph = None self . tb_formatter = None def _on_training_start ( self ) -> bool : self . tb_formatter = next ( formatter for formatter in self . logger . output_formats if isinstance ( formatter , TensorBoardOutputFormat )) return True def _on_step ( self ) -> bool : mood_scores = [ x [ \"mood_score\" ] for x in self . locals [ \"infos\" ]] highest_mood_score_index = np . argmax ( np . nan_to_num ( mood_scores )) highest_mood_score = mood_scores [ highest_mood_score_index ] if not isnan ( highest_mood_score ) and ( self . highest_mood_score == None or highest_mood_score > self . highest_mood_score ): self . highest_mood_score = highest_mood_score self . highest_mood_score_graph = copy . deepcopy ( self . locals [ \"infos\" ][ highest_mood_score_index ][ \"graph\" ]) self . got_new_highest_mood_score = True lowest_mood_score_index = np . argmin ( np . nan_to_num ( mood_scores , nan = 1000 )) lowest_mood_score = mood_scores [ lowest_mood_score_index ] if not isnan ( lowest_mood_score ) and ( self . lowest_mood_score == None or lowest_mood_score < self . lowest_mood_score ): self . lowest_mood_score = lowest_mood_score if self . n_calls % self . check_freq == 0 : self . logger . record ( 'rollout/highest_mood_score' , self . highest_mood_score ) self . logger . record ( 'rollout/lowest_mood_score' , self . lowest_mood_score ) if self . got_new_highest_mood_score : fig = draw_graph ( self . highest_mood_score_graph , show_graph = False ) self . logger . record ( \"graphs/highest_mood_score_graph\" , Figure ( fig , close = True ), exclude = ( \"stdout\" , \"log\" , \"json\" , \"csv\" )) graph_edge_list_string = \"\" for edge in edgelist . generate_edgelist ( self . highest_mood_score_graph , delimiter = \", \" , data = False ): graph_edge_list_string = graph_edge_list_string + f \"( { edge } ),&nbsp;\" graph_edge_list_string = graph_edge_list_string [: - 7 ] self . tb_formatter . writer . add_text ( \"graphs/highest_mood_score_graph\" , graph_edge_list_string , self . num_timesteps ) self . tb_formatter . writer . flush () self . got_new_highest_mood_score = False return True","title":"LogBestGraph"},{"location":"graphs/callbacks/callbacks/#backend.graphs.callbacks.callbacks.LogMoodScores","text":"Bases: BaseCallback Callback for logging the mean mood score of valid graphs the model generates to the TensorBoard log. NaN if the model didn't generate any valid graphs. Parameters: Name Type Description Default check_freq int Frequency of steps in which to log a new value. Defaults to number of steps per epoch. config['training']['steps_per_epoch'] Source code in backend/graphs/callbacks/callbacks.py 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 class LogMoodScores ( BaseCallback ): ''' Callback for logging the mean mood score of valid graphs the model generates to the TensorBoard log. NaN if the model didn't generate any valid graphs. Args: check_freq: Frequency of steps in which to log a new value. Defaults to number of steps per epoch. ''' def __init__ ( self , check_freq : int = config [ \"training\" ][ \"steps_per_epoch\" ]): super ( LogMoodScores , self ) . __init__ () self . check_freq = check_freq self . mood_scores = [] def _on_step ( self ) -> bool : mood_scores = [ x [ \"mood_score\" ] for x in self . locals [ \"infos\" ]] self . mood_scores . append ( mood_scores ) if self . n_calls % self . check_freq == 0 : mean_mood_score = np . nanmean ( self . mood_scores ) self . logger . record ( 'rollout/mean_mood_score' , mean_mood_score ) self . mood_scores = [] return True","title":"LogMoodScores"},{"location":"graphs/callbacks/callbacks/#backend.graphs.callbacks.callbacks.LogValidActions","text":"Bases: BaseCallback Callback for logging the ratio of valid actions the model takes to the TensorBoard log. Parameters: Name Type Description Default check_freq int Frequency of steps in which to log a new value. Defaults to number of steps per epoch. config['training']['steps_per_epoch'] Source code in backend/graphs/callbacks/callbacks.py 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 class LogValidActions ( BaseCallback ): ''' Callback for logging the ratio of valid actions the model takes to the TensorBoard log. Args: check_freq: Frequency of steps in which to log a new value. Defaults to number of steps per epoch. ''' def __init__ ( self , check_freq : int = config [ \"training\" ][ \"steps_per_epoch\" ]): super ( LogValidActions , self ) . __init__ () self . check_freq = check_freq self . valid_actions = [] def _on_step ( self ) -> bool : self . valid_actions . append ([ x [ \"action_valid\" ] for x in self . locals [ \"infos\" ]]) if self . n_calls % self . check_freq == 0 : _ , counts = np . unique ( self . valid_actions , return_counts = True ) valid_action_ratio = counts [ 1 ] / ( counts [ 0 ] + counts [ 1 ]) self . logger . record ( 'rollout/valid_action_ratio' , valid_action_ratio ) self . valid_actions = [] return True","title":"LogValidActions"},{"location":"graphs/callbacks/callbacks/#backend.graphs.callbacks.callbacks.LogValidGraphs","text":"Bases: BaseCallback Callback for logging the ratio of valid graphs the model generates to the TensorBoard log. Parameters: Name Type Description Default check_freq int Frequency of steps in which to log a new value. Defaults to number of steps per epoch. config['training']['steps_per_epoch'] Source code in backend/graphs/callbacks/callbacks.py 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 class LogValidGraphs ( BaseCallback ): ''' Callback for logging the ratio of valid graphs the model generates to the TensorBoard log. Args: check_freq: Frequency of steps in which to log a new value. Defaults to number of steps per epoch. ''' def __init__ ( self , check_freq : int = config [ \"training\" ][ \"steps_per_epoch\" ]): super ( LogValidGraphs , self ) . __init__ () self . check_freq = check_freq self . valid_graphs = [] def _on_step ( self ) -> bool : self . valid_graphs . append ([ x [ \"graph_valid\" ] for x in self . locals [ \"infos\" ]]) if self . n_calls % self . check_freq == 0 : u , c = np . unique ( self . valid_graphs , return_counts = True ) counts = dict ( zip ( u , c )) n_valid = counts [ 1 ] if 1 in counts . keys () else 0 n_invalid = counts [ 0 ] if 0 in counts . keys () else 0 valid_graph_ratio = n_valid / ( n_invalid + n_valid ) self . logger . record ( 'rollout/valid_graph_ratio' , valid_graph_ratio ) self . valid_graphs = [] return True","title":"LogValidGraphs"},{"location":"graphs/callbacks/callbacks/#backend.graphs.callbacks.callbacks.SaveOnBestTrainingRewardCallback","text":"Bases: BaseCallback Callback for saving a model (the check is done every check_freq steps) based on the training reward. Parameters: Name Type Description Default log_dir str Path to the folder where the model will be saved. It must contains the file created by the Monitor wrapper. required check_freq int Frequency of steps in which to check if a better model can be saved. Defaults to number of steps per epoch. config['training']['steps_per_epoch'] verbose int Verbosity level. 1 Source code in backend/graphs/callbacks/callbacks.py 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 class SaveOnBestTrainingRewardCallback ( BaseCallback ): ''' Callback for saving a model (the check is done every ``check_freq`` steps) based on the training reward. Args: log_dir: Path to the folder where the model will be saved. It must contains the file created by the ``Monitor`` wrapper. check_freq: Frequency of steps in which to check if a better model can be saved. Defaults to number of steps per epoch. verbose: Verbosity level. ''' def __init__ ( self , log_dir : str , check_freq : int = config [ \"training\" ][ \"steps_per_epoch\" ], verbose : int = 1 ): super ( SaveOnBestTrainingRewardCallback , self ) . __init__ ( verbose ) self . check_freq = check_freq self . log_dir = log_dir self . save_path = os . path . join ( log_dir , 'best_model' ) self . best_mean_reward = - np . inf def _init_callback ( self ) -> None : # Create folder if needed if self . save_path is not None : os . makedirs ( self . save_path , exist_ok = True ) def _on_step ( self ) -> bool : if self . n_calls % self . check_freq == 0 : # Retrieve training reward x , y = ts2xy ( load_results ( self . log_dir ), 'timesteps' ) if len ( x ) > 0 : # Mean training reward over the last 100 episodes mean_reward = np . mean ( y [ - 100 :]) if self . verbose > 0 : print ( f \"Num timesteps: { self . num_timesteps } \" ) print ( f \"Best mean reward: { self . best_mean_reward : .2f } - Last mean reward per episode: { mean_reward : .2f } \" ) # New best model, you could save the agent here if mean_reward > self . best_mean_reward : self . best_mean_reward = mean_reward # Example for saving best model if self . verbose > 0 : print ( f \"Saving new best model to { self . save_path } \" ) self . model . save ( self . save_path ) return True","title":"SaveOnBestTrainingRewardCallback"},{"location":"graphs/data/edge_score_matrix/","text":"","title":"Edge score matrix"},{"location":"graphs/envs/graph_env/","text":"GraphEnv Bases: gym . Env This class describes the environment that the agent interacts with and gets its feedback from (in form of rewards). It holds a representation of the seating plan graph and updates it according to the agent's actions. Note: Please use the init method to initialize the environment correctly. Source code in backend/graphs/envs/graph_env.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 class GraphEnv ( gym . Env ): ''' This class describes the environment that the agent interacts with and gets its feedback from (in form of rewards). It holds a representation of the seating plan graph and updates it according to the agent's actions. *Note: Please use the `init` method to initialize the environment correctly.* ''' def __init__ ( self ): # Legacy initialization function without args. # *Do not use this function! Please use the `init` method instead.* pass def init ( self , base_graph : nx . Graph , preconnect_nodes_probability = 0 ): ''' Initializes the environment. Args: base_graph: The seating plan graph the environment starts with and is reset to. It should contain all nodes and may also have edges. preconnect_nodes_probability (`float`, optional): The probability with wich a random number of edges get added the seating plan graph after resetting the environment. Defaults to 0. ''' self . config = config self . base_graph = base_graph self . graph = copy . deepcopy ( self . base_graph ) self . preconnect_nodes_probability = preconnect_nodes_probability self . counter = 0 self . num_nodes = self . base_graph . number_of_nodes () self . max_edges = ((( self . num_nodes * 3 ) - 4 ) / 2 ) self . action_space = gym . spaces . MultiDiscrete ([ self . num_nodes , self . num_nodes ]) self . observation_space = gym . spaces . Dict ({ 'adj' : gym . spaces . Box ( low = 0 , high = self . num_nodes , shape = ( 1 , self . num_nodes , self . num_nodes ), dtype = np . uint8 ), 'node' : gym . spaces . Box ( low = 0 , high = self . num_nodes , shape = ( 1 , self . num_nodes , self . config [ 'data' ][ 'num_node_features' ]), dtype = np . uint8 ) }) self . level = 0 # for curriculum learning, level starts with 0, and increase afterwards # draw graph if self . config [ 'debugging' ][ 'draw_graph' ]: draw_graph ( self . graph , layout = None ) def step ( self , action ): ''' Updates the environment according to the given `action` if it's valid. Sets rewards for the agent. Once the graph has enough edges, it sets terminal signal that resets the environment. Args: action: The action to manipulate the seating plan graph. An array holding two integers for the IDs of the nodes to connect. Returns: ob: The observation of the seating plan graph as `dict` with adjacency matrix (adj) and node matrix with features (node). reward: The reward calculated in the current step. new: The terminal signal to reset the environment. info: A dict with useful information for evaluation. ''' # init info = {} # info we care about graph_is_valid = None mood_scores = [] # take action or not edge_added = self . _add_edge ( action ) # print actions if self . config [ 'debugging' ][ 'print_actions' ]: print ( action ) # get observation ob = self . get_observation () # wheter to stop after this step stop = self . graph . number_of_edges () >= ( (( self . config [ 'data' ][ 'num_nodes' ] * 3 ) - 4 ) / 2 ) or self . counter >= self . config [ 'training' ][ 'max_steps' ] # calculate intermediate rewards if edge_added : reward_step = self . config [ 'rewards' ][ 'step_edge_correct' ] else : reward_step = self . config [ 'rewards' ][ 'step_edge_incorrect' ] # calculate and use terminal reward if stop : new = True # end of episode graph_is_valid = valid_table_graph ( self . graph ) if graph_is_valid : mood_scores = get_edge_scores ( self . graph . edges ()) reward_terminal = ( np . sum ( mood_scores ) - self . config [ 'rewards' ][ 'score_min' ]) / ( self . config [ 'rewards' ][ 'score_max' ] - self . config [ 'rewards' ][ 'score_min' ]) * self . config [ 'rewards' ][ 'terminal_valid_score_multiplier' ] # draw finalized graph if self . config [ 'debugging' ][ 'draw_correct_graphs' ]: print ( reward_terminal ) draw_graph ( self . graph ) else : reward_terminal = self . config [ 'rewards' ][ 'terminal_invalid' ] reward = reward_step + reward_terminal # print terminal graph information info [ 'final_stat' ] = reward_terminal info [ 'reward' ] = reward info [ 'stop' ] = stop # use stepwise reward else : new = False reward = reward_step self . counter += 1 if new : self . counter = 0 info [ 'graph' ] = self . graph info [ 'action_valid' ] = int ( edge_added ) info [ 'graph_valid' ] = int ( graph_is_valid ) if graph_is_valid != None else - np . inf info [ 'mood_score' ] = np . sum ( mood_scores ) if len ( mood_scores ) > 0 else np . nan if self . config [ 'debugging' ][ 'print_actions' ]: print ( reward ) # draw graph if self . config [ 'debugging' ][ 'draw_graph' ]: draw_graph ( self . graph , layout = None ) return ob , reward , new , info def reset ( self ): ''' Resets the environment's seating plan graph to given `self.base_graph` and with the probability set by `self.preconnect_nodes_probability` adds random number of edges (between 1 and `max_edges` - 1). ''' self . graph = copy . deepcopy ( self . base_graph ) # preconnecting nodes simulates user input if random . random () < self . preconnect_nodes_probability : # create list of shuffled node ids graph_nodes = np . array ( self . graph ) random . shuffle ( graph_nodes ) # generate grid graph to get valid table structure grid_graph = nx . grid_graph (( 2 , len ( graph_nodes ) // 2 )) # convert positional ids from grid graph eg. (2, 1) to indices eg. 12 # use these indices in shuffeled node array to randomly assign new id # and generate edge list for the random table graph graph_edges = [( graph_nodes [ edge [ 0 ][ 0 ] + len ( graph_nodes ) // 2 * edge [ 0 ][ 1 ]], graph_nodes [ edge [ 1 ][ 0 ] + len ( graph_nodes ) // 2 * edge [ 1 ][ 1 ]]) for edge in grid_graph . edges ] # only add some random amount of edges to achieve incomplete table graph self . graph . add_edges_from ( random . sample ( graph_edges , k = random . randint ( 1 , len ( graph_edges ) - 1 ))) if self . config [ 'debugging' ][ 'draw_preconnected_graphs' ]: print ( \"preconnected graph\" ) draw_graph ( self . graph ) self . counter = 0 ob = self . get_observation () return ob def render ( self ): return def _add_edge ( self , action ): \"\"\" Adds only valid edges between the given nodes. Args: action: Array of two nodes to connect. Returns: True if valid edge was added successfully. False if invalid edge wasn't added successfully. \"\"\" if self . graph . has_edge ( int ( action [ 0 ]), int ( action [ 1 ])) or int ( action [ 0 ]) == int ( action [ 1 ]) or self . graph . degree ( action [ 0 ]) >= 3 or self . graph . degree ( action [ 1 ]) >= 3 : return False else : graph_old = copy . deepcopy ( self . graph ) self . graph . add_edge ( int ( action [ 0 ]), int ( action [ 1 ])) if not nx . is_bipartite ( self . graph ): self . graph = graph_old return False return True def get_observation ( self ): \"\"\" Converts the seating plan graph with type `nx.Graph` to dict with adjacency matrix and node matrix with features. Returns: ob: Observation dict where ob['adj'] is E with dim 1 x n x n and ob['node'] is F with dim 1 x n x m. \"\"\" ob = {} ob [ 'adj' ] = np . expand_dims ( nx . adjacency_matrix ( self . graph ) . todense (), axis = 0 ) ob [ 'node' ] = np . expand_dims ( np . array ([[ feature for feature in node [ 1 ] . values ()] for node in self . graph . nodes ( data = True )]), axis = 0 ) return ob get_observation () Converts the seating plan graph with type nx.Graph to dict with adjacency matrix and node matrix with features. Returns: Name Type Description ob Observation dict where ob['adj'] is E with dim 1 x n x n and ob['node'] is F with dim 1 x n x m. Source code in backend/graphs/envs/graph_env.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 def get_observation ( self ): \"\"\" Converts the seating plan graph with type `nx.Graph` to dict with adjacency matrix and node matrix with features. Returns: ob: Observation dict where ob['adj'] is E with dim 1 x n x n and ob['node'] is F with dim 1 x n x m. \"\"\" ob = {} ob [ 'adj' ] = np . expand_dims ( nx . adjacency_matrix ( self . graph ) . todense (), axis = 0 ) ob [ 'node' ] = np . expand_dims ( np . array ([[ feature for feature in node [ 1 ] . values ()] for node in self . graph . nodes ( data = True )]), axis = 0 ) return ob init ( base_graph , preconnect_nodes_probability = 0 ) Initializes the environment. Parameters: Name Type Description Default base_graph nx . Graph The seating plan graph the environment starts with and is reset to. It should contain all nodes and may also have edges. required preconnect_nodes_probability `float` The probability with wich a random number of edges get added the seating plan graph after resetting the environment. Defaults to 0. 0 Source code in backend/graphs/envs/graph_env.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def init ( self , base_graph : nx . Graph , preconnect_nodes_probability = 0 ): ''' Initializes the environment. Args: base_graph: The seating plan graph the environment starts with and is reset to. It should contain all nodes and may also have edges. preconnect_nodes_probability (`float`, optional): The probability with wich a random number of edges get added the seating plan graph after resetting the environment. Defaults to 0. ''' self . config = config self . base_graph = base_graph self . graph = copy . deepcopy ( self . base_graph ) self . preconnect_nodes_probability = preconnect_nodes_probability self . counter = 0 self . num_nodes = self . base_graph . number_of_nodes () self . max_edges = ((( self . num_nodes * 3 ) - 4 ) / 2 ) self . action_space = gym . spaces . MultiDiscrete ([ self . num_nodes , self . num_nodes ]) self . observation_space = gym . spaces . Dict ({ 'adj' : gym . spaces . Box ( low = 0 , high = self . num_nodes , shape = ( 1 , self . num_nodes , self . num_nodes ), dtype = np . uint8 ), 'node' : gym . spaces . Box ( low = 0 , high = self . num_nodes , shape = ( 1 , self . num_nodes , self . config [ 'data' ][ 'num_node_features' ]), dtype = np . uint8 ) }) self . level = 0 # for curriculum learning, level starts with 0, and increase afterwards # draw graph if self . config [ 'debugging' ][ 'draw_graph' ]: draw_graph ( self . graph , layout = None ) reset () Resets the environment's seating plan graph to given self.base_graph and with the probability set by self.preconnect_nodes_probability adds random number of edges (between 1 and max_edges - 1). Source code in backend/graphs/envs/graph_env.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 def reset ( self ): ''' Resets the environment's seating plan graph to given `self.base_graph` and with the probability set by `self.preconnect_nodes_probability` adds random number of edges (between 1 and `max_edges` - 1). ''' self . graph = copy . deepcopy ( self . base_graph ) # preconnecting nodes simulates user input if random . random () < self . preconnect_nodes_probability : # create list of shuffled node ids graph_nodes = np . array ( self . graph ) random . shuffle ( graph_nodes ) # generate grid graph to get valid table structure grid_graph = nx . grid_graph (( 2 , len ( graph_nodes ) // 2 )) # convert positional ids from grid graph eg. (2, 1) to indices eg. 12 # use these indices in shuffeled node array to randomly assign new id # and generate edge list for the random table graph graph_edges = [( graph_nodes [ edge [ 0 ][ 0 ] + len ( graph_nodes ) // 2 * edge [ 0 ][ 1 ]], graph_nodes [ edge [ 1 ][ 0 ] + len ( graph_nodes ) // 2 * edge [ 1 ][ 1 ]]) for edge in grid_graph . edges ] # only add some random amount of edges to achieve incomplete table graph self . graph . add_edges_from ( random . sample ( graph_edges , k = random . randint ( 1 , len ( graph_edges ) - 1 ))) if self . config [ 'debugging' ][ 'draw_preconnected_graphs' ]: print ( \"preconnected graph\" ) draw_graph ( self . graph ) self . counter = 0 ob = self . get_observation () return ob step ( action ) Updates the environment according to the given action if it's valid. Sets rewards for the agent. Once the graph has enough edges, it sets terminal signal that resets the environment. Parameters: Name Type Description Default action The action to manipulate the seating plan graph. An array holding two integers for the IDs of the nodes to connect. required Returns: Name Type Description ob The observation of the seating plan graph as dict with adjacency matrix (adj) and node matrix with features (node). reward The reward calculated in the current step. new The terminal signal to reset the environment. info A dict with useful information for evaluation. Source code in backend/graphs/envs/graph_env.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def step ( self , action ): ''' Updates the environment according to the given `action` if it's valid. Sets rewards for the agent. Once the graph has enough edges, it sets terminal signal that resets the environment. Args: action: The action to manipulate the seating plan graph. An array holding two integers for the IDs of the nodes to connect. Returns: ob: The observation of the seating plan graph as `dict` with adjacency matrix (adj) and node matrix with features (node). reward: The reward calculated in the current step. new: The terminal signal to reset the environment. info: A dict with useful information for evaluation. ''' # init info = {} # info we care about graph_is_valid = None mood_scores = [] # take action or not edge_added = self . _add_edge ( action ) # print actions if self . config [ 'debugging' ][ 'print_actions' ]: print ( action ) # get observation ob = self . get_observation () # wheter to stop after this step stop = self . graph . number_of_edges () >= ( (( self . config [ 'data' ][ 'num_nodes' ] * 3 ) - 4 ) / 2 ) or self . counter >= self . config [ 'training' ][ 'max_steps' ] # calculate intermediate rewards if edge_added : reward_step = self . config [ 'rewards' ][ 'step_edge_correct' ] else : reward_step = self . config [ 'rewards' ][ 'step_edge_incorrect' ] # calculate and use terminal reward if stop : new = True # end of episode graph_is_valid = valid_table_graph ( self . graph ) if graph_is_valid : mood_scores = get_edge_scores ( self . graph . edges ()) reward_terminal = ( np . sum ( mood_scores ) - self . config [ 'rewards' ][ 'score_min' ]) / ( self . config [ 'rewards' ][ 'score_max' ] - self . config [ 'rewards' ][ 'score_min' ]) * self . config [ 'rewards' ][ 'terminal_valid_score_multiplier' ] # draw finalized graph if self . config [ 'debugging' ][ 'draw_correct_graphs' ]: print ( reward_terminal ) draw_graph ( self . graph ) else : reward_terminal = self . config [ 'rewards' ][ 'terminal_invalid' ] reward = reward_step + reward_terminal # print terminal graph information info [ 'final_stat' ] = reward_terminal info [ 'reward' ] = reward info [ 'stop' ] = stop # use stepwise reward else : new = False reward = reward_step self . counter += 1 if new : self . counter = 0 info [ 'graph' ] = self . graph info [ 'action_valid' ] = int ( edge_added ) info [ 'graph_valid' ] = int ( graph_is_valid ) if graph_is_valid != None else - np . inf info [ 'mood_score' ] = np . sum ( mood_scores ) if len ( mood_scores ) > 0 else np . nan if self . config [ 'debugging' ][ 'print_actions' ]: print ( reward ) # draw graph if self . config [ 'debugging' ][ 'draw_graph' ]: draw_graph ( self . graph , layout = None ) return ob , reward , new , info","title":"Graph env"},{"location":"graphs/envs/graph_env/#backend.graphs.envs.graph_env.GraphEnv","text":"Bases: gym . Env This class describes the environment that the agent interacts with and gets its feedback from (in form of rewards). It holds a representation of the seating plan graph and updates it according to the agent's actions. Note: Please use the init method to initialize the environment correctly. Source code in backend/graphs/envs/graph_env.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 class GraphEnv ( gym . Env ): ''' This class describes the environment that the agent interacts with and gets its feedback from (in form of rewards). It holds a representation of the seating plan graph and updates it according to the agent's actions. *Note: Please use the `init` method to initialize the environment correctly.* ''' def __init__ ( self ): # Legacy initialization function without args. # *Do not use this function! Please use the `init` method instead.* pass def init ( self , base_graph : nx . Graph , preconnect_nodes_probability = 0 ): ''' Initializes the environment. Args: base_graph: The seating plan graph the environment starts with and is reset to. It should contain all nodes and may also have edges. preconnect_nodes_probability (`float`, optional): The probability with wich a random number of edges get added the seating plan graph after resetting the environment. Defaults to 0. ''' self . config = config self . base_graph = base_graph self . graph = copy . deepcopy ( self . base_graph ) self . preconnect_nodes_probability = preconnect_nodes_probability self . counter = 0 self . num_nodes = self . base_graph . number_of_nodes () self . max_edges = ((( self . num_nodes * 3 ) - 4 ) / 2 ) self . action_space = gym . spaces . MultiDiscrete ([ self . num_nodes , self . num_nodes ]) self . observation_space = gym . spaces . Dict ({ 'adj' : gym . spaces . Box ( low = 0 , high = self . num_nodes , shape = ( 1 , self . num_nodes , self . num_nodes ), dtype = np . uint8 ), 'node' : gym . spaces . Box ( low = 0 , high = self . num_nodes , shape = ( 1 , self . num_nodes , self . config [ 'data' ][ 'num_node_features' ]), dtype = np . uint8 ) }) self . level = 0 # for curriculum learning, level starts with 0, and increase afterwards # draw graph if self . config [ 'debugging' ][ 'draw_graph' ]: draw_graph ( self . graph , layout = None ) def step ( self , action ): ''' Updates the environment according to the given `action` if it's valid. Sets rewards for the agent. Once the graph has enough edges, it sets terminal signal that resets the environment. Args: action: The action to manipulate the seating plan graph. An array holding two integers for the IDs of the nodes to connect. Returns: ob: The observation of the seating plan graph as `dict` with adjacency matrix (adj) and node matrix with features (node). reward: The reward calculated in the current step. new: The terminal signal to reset the environment. info: A dict with useful information for evaluation. ''' # init info = {} # info we care about graph_is_valid = None mood_scores = [] # take action or not edge_added = self . _add_edge ( action ) # print actions if self . config [ 'debugging' ][ 'print_actions' ]: print ( action ) # get observation ob = self . get_observation () # wheter to stop after this step stop = self . graph . number_of_edges () >= ( (( self . config [ 'data' ][ 'num_nodes' ] * 3 ) - 4 ) / 2 ) or self . counter >= self . config [ 'training' ][ 'max_steps' ] # calculate intermediate rewards if edge_added : reward_step = self . config [ 'rewards' ][ 'step_edge_correct' ] else : reward_step = self . config [ 'rewards' ][ 'step_edge_incorrect' ] # calculate and use terminal reward if stop : new = True # end of episode graph_is_valid = valid_table_graph ( self . graph ) if graph_is_valid : mood_scores = get_edge_scores ( self . graph . edges ()) reward_terminal = ( np . sum ( mood_scores ) - self . config [ 'rewards' ][ 'score_min' ]) / ( self . config [ 'rewards' ][ 'score_max' ] - self . config [ 'rewards' ][ 'score_min' ]) * self . config [ 'rewards' ][ 'terminal_valid_score_multiplier' ] # draw finalized graph if self . config [ 'debugging' ][ 'draw_correct_graphs' ]: print ( reward_terminal ) draw_graph ( self . graph ) else : reward_terminal = self . config [ 'rewards' ][ 'terminal_invalid' ] reward = reward_step + reward_terminal # print terminal graph information info [ 'final_stat' ] = reward_terminal info [ 'reward' ] = reward info [ 'stop' ] = stop # use stepwise reward else : new = False reward = reward_step self . counter += 1 if new : self . counter = 0 info [ 'graph' ] = self . graph info [ 'action_valid' ] = int ( edge_added ) info [ 'graph_valid' ] = int ( graph_is_valid ) if graph_is_valid != None else - np . inf info [ 'mood_score' ] = np . sum ( mood_scores ) if len ( mood_scores ) > 0 else np . nan if self . config [ 'debugging' ][ 'print_actions' ]: print ( reward ) # draw graph if self . config [ 'debugging' ][ 'draw_graph' ]: draw_graph ( self . graph , layout = None ) return ob , reward , new , info def reset ( self ): ''' Resets the environment's seating plan graph to given `self.base_graph` and with the probability set by `self.preconnect_nodes_probability` adds random number of edges (between 1 and `max_edges` - 1). ''' self . graph = copy . deepcopy ( self . base_graph ) # preconnecting nodes simulates user input if random . random () < self . preconnect_nodes_probability : # create list of shuffled node ids graph_nodes = np . array ( self . graph ) random . shuffle ( graph_nodes ) # generate grid graph to get valid table structure grid_graph = nx . grid_graph (( 2 , len ( graph_nodes ) // 2 )) # convert positional ids from grid graph eg. (2, 1) to indices eg. 12 # use these indices in shuffeled node array to randomly assign new id # and generate edge list for the random table graph graph_edges = [( graph_nodes [ edge [ 0 ][ 0 ] + len ( graph_nodes ) // 2 * edge [ 0 ][ 1 ]], graph_nodes [ edge [ 1 ][ 0 ] + len ( graph_nodes ) // 2 * edge [ 1 ][ 1 ]]) for edge in grid_graph . edges ] # only add some random amount of edges to achieve incomplete table graph self . graph . add_edges_from ( random . sample ( graph_edges , k = random . randint ( 1 , len ( graph_edges ) - 1 ))) if self . config [ 'debugging' ][ 'draw_preconnected_graphs' ]: print ( \"preconnected graph\" ) draw_graph ( self . graph ) self . counter = 0 ob = self . get_observation () return ob def render ( self ): return def _add_edge ( self , action ): \"\"\" Adds only valid edges between the given nodes. Args: action: Array of two nodes to connect. Returns: True if valid edge was added successfully. False if invalid edge wasn't added successfully. \"\"\" if self . graph . has_edge ( int ( action [ 0 ]), int ( action [ 1 ])) or int ( action [ 0 ]) == int ( action [ 1 ]) or self . graph . degree ( action [ 0 ]) >= 3 or self . graph . degree ( action [ 1 ]) >= 3 : return False else : graph_old = copy . deepcopy ( self . graph ) self . graph . add_edge ( int ( action [ 0 ]), int ( action [ 1 ])) if not nx . is_bipartite ( self . graph ): self . graph = graph_old return False return True def get_observation ( self ): \"\"\" Converts the seating plan graph with type `nx.Graph` to dict with adjacency matrix and node matrix with features. Returns: ob: Observation dict where ob['adj'] is E with dim 1 x n x n and ob['node'] is F with dim 1 x n x m. \"\"\" ob = {} ob [ 'adj' ] = np . expand_dims ( nx . adjacency_matrix ( self . graph ) . todense (), axis = 0 ) ob [ 'node' ] = np . expand_dims ( np . array ([[ feature for feature in node [ 1 ] . values ()] for node in self . graph . nodes ( data = True )]), axis = 0 ) return ob","title":"GraphEnv"},{"location":"graphs/envs/graph_env/#backend.graphs.envs.graph_env.GraphEnv.get_observation","text":"Converts the seating plan graph with type nx.Graph to dict with adjacency matrix and node matrix with features. Returns: Name Type Description ob Observation dict where ob['adj'] is E with dim 1 x n x n and ob['node'] is F with dim 1 x n x m. Source code in backend/graphs/envs/graph_env.py 200 201 202 203 204 205 206 207 208 209 210 211 212 213 def get_observation ( self ): \"\"\" Converts the seating plan graph with type `nx.Graph` to dict with adjacency matrix and node matrix with features. Returns: ob: Observation dict where ob['adj'] is E with dim 1 x n x n and ob['node'] is F with dim 1 x n x m. \"\"\" ob = {} ob [ 'adj' ] = np . expand_dims ( nx . adjacency_matrix ( self . graph ) . todense (), axis = 0 ) ob [ 'node' ] = np . expand_dims ( np . array ([[ feature for feature in node [ 1 ] . values ()] for node in self . graph . nodes ( data = True )]), axis = 0 ) return ob","title":"get_observation()"},{"location":"graphs/envs/graph_env/#backend.graphs.envs.graph_env.GraphEnv.init","text":"Initializes the environment. Parameters: Name Type Description Default base_graph nx . Graph The seating plan graph the environment starts with and is reset to. It should contain all nodes and may also have edges. required preconnect_nodes_probability `float` The probability with wich a random number of edges get added the seating plan graph after resetting the environment. Defaults to 0. 0 Source code in backend/graphs/envs/graph_env.py 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 def init ( self , base_graph : nx . Graph , preconnect_nodes_probability = 0 ): ''' Initializes the environment. Args: base_graph: The seating plan graph the environment starts with and is reset to. It should contain all nodes and may also have edges. preconnect_nodes_probability (`float`, optional): The probability with wich a random number of edges get added the seating plan graph after resetting the environment. Defaults to 0. ''' self . config = config self . base_graph = base_graph self . graph = copy . deepcopy ( self . base_graph ) self . preconnect_nodes_probability = preconnect_nodes_probability self . counter = 0 self . num_nodes = self . base_graph . number_of_nodes () self . max_edges = ((( self . num_nodes * 3 ) - 4 ) / 2 ) self . action_space = gym . spaces . MultiDiscrete ([ self . num_nodes , self . num_nodes ]) self . observation_space = gym . spaces . Dict ({ 'adj' : gym . spaces . Box ( low = 0 , high = self . num_nodes , shape = ( 1 , self . num_nodes , self . num_nodes ), dtype = np . uint8 ), 'node' : gym . spaces . Box ( low = 0 , high = self . num_nodes , shape = ( 1 , self . num_nodes , self . config [ 'data' ][ 'num_node_features' ]), dtype = np . uint8 ) }) self . level = 0 # for curriculum learning, level starts with 0, and increase afterwards # draw graph if self . config [ 'debugging' ][ 'draw_graph' ]: draw_graph ( self . graph , layout = None )","title":"init()"},{"location":"graphs/envs/graph_env/#backend.graphs.envs.graph_env.GraphEnv.reset","text":"Resets the environment's seating plan graph to given self.base_graph and with the probability set by self.preconnect_nodes_probability adds random number of edges (between 1 and max_edges - 1). Source code in backend/graphs/envs/graph_env.py 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 def reset ( self ): ''' Resets the environment's seating plan graph to given `self.base_graph` and with the probability set by `self.preconnect_nodes_probability` adds random number of edges (between 1 and `max_edges` - 1). ''' self . graph = copy . deepcopy ( self . base_graph ) # preconnecting nodes simulates user input if random . random () < self . preconnect_nodes_probability : # create list of shuffled node ids graph_nodes = np . array ( self . graph ) random . shuffle ( graph_nodes ) # generate grid graph to get valid table structure grid_graph = nx . grid_graph (( 2 , len ( graph_nodes ) // 2 )) # convert positional ids from grid graph eg. (2, 1) to indices eg. 12 # use these indices in shuffeled node array to randomly assign new id # and generate edge list for the random table graph graph_edges = [( graph_nodes [ edge [ 0 ][ 0 ] + len ( graph_nodes ) // 2 * edge [ 0 ][ 1 ]], graph_nodes [ edge [ 1 ][ 0 ] + len ( graph_nodes ) // 2 * edge [ 1 ][ 1 ]]) for edge in grid_graph . edges ] # only add some random amount of edges to achieve incomplete table graph self . graph . add_edges_from ( random . sample ( graph_edges , k = random . randint ( 1 , len ( graph_edges ) - 1 ))) if self . config [ 'debugging' ][ 'draw_preconnected_graphs' ]: print ( \"preconnected graph\" ) draw_graph ( self . graph ) self . counter = 0 ob = self . get_observation () return ob","title":"reset()"},{"location":"graphs/envs/graph_env/#backend.graphs.envs.graph_env.GraphEnv.step","text":"Updates the environment according to the given action if it's valid. Sets rewards for the agent. Once the graph has enough edges, it sets terminal signal that resets the environment. Parameters: Name Type Description Default action The action to manipulate the seating plan graph. An array holding two integers for the IDs of the nodes to connect. required Returns: Name Type Description ob The observation of the seating plan graph as dict with adjacency matrix (adj) and node matrix with features (node). reward The reward calculated in the current step. new The terminal signal to reset the environment. info A dict with useful information for evaluation. Source code in backend/graphs/envs/graph_env.py 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 def step ( self , action ): ''' Updates the environment according to the given `action` if it's valid. Sets rewards for the agent. Once the graph has enough edges, it sets terminal signal that resets the environment. Args: action: The action to manipulate the seating plan graph. An array holding two integers for the IDs of the nodes to connect. Returns: ob: The observation of the seating plan graph as `dict` with adjacency matrix (adj) and node matrix with features (node). reward: The reward calculated in the current step. new: The terminal signal to reset the environment. info: A dict with useful information for evaluation. ''' # init info = {} # info we care about graph_is_valid = None mood_scores = [] # take action or not edge_added = self . _add_edge ( action ) # print actions if self . config [ 'debugging' ][ 'print_actions' ]: print ( action ) # get observation ob = self . get_observation () # wheter to stop after this step stop = self . graph . number_of_edges () >= ( (( self . config [ 'data' ][ 'num_nodes' ] * 3 ) - 4 ) / 2 ) or self . counter >= self . config [ 'training' ][ 'max_steps' ] # calculate intermediate rewards if edge_added : reward_step = self . config [ 'rewards' ][ 'step_edge_correct' ] else : reward_step = self . config [ 'rewards' ][ 'step_edge_incorrect' ] # calculate and use terminal reward if stop : new = True # end of episode graph_is_valid = valid_table_graph ( self . graph ) if graph_is_valid : mood_scores = get_edge_scores ( self . graph . edges ()) reward_terminal = ( np . sum ( mood_scores ) - self . config [ 'rewards' ][ 'score_min' ]) / ( self . config [ 'rewards' ][ 'score_max' ] - self . config [ 'rewards' ][ 'score_min' ]) * self . config [ 'rewards' ][ 'terminal_valid_score_multiplier' ] # draw finalized graph if self . config [ 'debugging' ][ 'draw_correct_graphs' ]: print ( reward_terminal ) draw_graph ( self . graph ) else : reward_terminal = self . config [ 'rewards' ][ 'terminal_invalid' ] reward = reward_step + reward_terminal # print terminal graph information info [ 'final_stat' ] = reward_terminal info [ 'reward' ] = reward info [ 'stop' ] = stop # use stepwise reward else : new = False reward = reward_step self . counter += 1 if new : self . counter = 0 info [ 'graph' ] = self . graph info [ 'action_valid' ] = int ( edge_added ) info [ 'graph_valid' ] = int ( graph_is_valid ) if graph_is_valid != None else - np . inf info [ 'mood_score' ] = np . sum ( mood_scores ) if len ( mood_scores ) > 0 else np . nan if self . config [ 'debugging' ][ 'print_actions' ]: print ( reward ) # draw graph if self . config [ 'debugging' ][ 'draw_graph' ]: draw_graph ( self . graph , layout = None ) return ob , reward , new , info","title":"step()"},{"location":"graphs/evaluation/evaluation/","text":"calculate_age_score ( age_1 , age_2 ) Calculates the age score of the edge. The age score is calculated as followed: if age group difference is 0, score is 1 if age group difference is 1, score is 0.5 if age group difference is 2 or more, score is 0 Parameters: Name Type Description Default age_1 int Age group value of node 1. required age_2 int Age group value of node 2. required Returns: Type Description float The age score. Source code in backend/graphs/evaluation/evaluation.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 def calculate_age_score ( age_1 : int , age_2 : int ) -> float : ''' Calculates the age score of the edge. The age score is calculated as followed: - if age group difference is 0, score is 1 - if age group difference is 1, score is 0.5 - if age group difference is 2 or more, score is 0 Args: age_1 (int): Age group value of node 1. age_2 (int): Age group value of node 2. Returns: The age score. ''' difference = abs ( age_1 - age_2 ) if difference == 0 : return 1.0 elif difference == 1 : return 0.5 else : return 0.0 calculate_country_score ( country_1 , country_2 ) Calculates the country score of the edge. The country score is calculated as followed: if country is the same, score is 1 if country is different but its language is the same, score is 0.5 if country and its language is different, score is 0 Country codes and language: 0: Germany (german) 1: Swiss (german) 2: Spain (spanish) 3: Mexico (spanish) Parameters: Name Type Description Default country_1 int Country value of node 1. required country_2 int Country value of node 2. required Returns: Type Description float The country score. Source code in backend/graphs/evaluation/evaluation.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def calculate_country_score ( country_1 : int , country_2 : int ) -> float : ''' Calculates the country score of the edge. The country score is calculated as followed: - if country is the same, score is 1 - if country is different but its language is the same, score is 0.5 - if country and its language is different, score is 0 Country codes and language: - 0: Germany (german) - 1: Swiss (german) - 2: Spain (spanish) - 3: Mexico (spanish) Args: country_1 (int): Country value of node 1. country_2 (int): Country value of node 2. Returns: The country score. ''' if country_1 == country_2 : return 1.0 elif ( country_1 ** 2 + country_2 ** 2 ) == ( 0 ** 2 + 1 ** 2 ) or ( country_1 ** 2 + country_2 ** 2 ) == ( 2 ** 2 + 3 ** 2 ): return 0.5 else : return 0.0 calculate_drinker_score ( drinker_1 , drinker_2 ) Calculates the drinker score of the edge. The drinker score is calculated as followed: if drinker value is the same, score is 1 else, score is 0 Parameters: Name Type Description Default drinker_1 int drinker value of node 1. required drinker_2 int drinker value of node 2. required Returns: Type Description float The drinker score. Source code in backend/graphs/evaluation/evaluation.py 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 def calculate_drinker_score ( drinker_1 : int , drinker_2 : int ) -> float : ''' Calculates the drinker score of the edge. The drinker score is calculated as followed: - if drinker value is the same, score is 1 - else, score is 0 Args: drinker_1 (int): drinker value of node 1. drinker_2 (int): drinker value of node 2. Returns: The drinker score. ''' return 1.0 if drinker_1 == drinker_2 else 0.0 calculate_edge_score_matrix ( nodes ) Calculates the matrix containing the mood scores of every node pair. See calculate_mood_score method for how a mood score is calculated between two nodes. Parameters: Name Type Description Default nodes The list of nodes with their features. required Returns: Type Description The edge score matrix. Source code in backend/graphs/evaluation/evaluation.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def calculate_edge_score_matrix ( nodes ): ''' Calculates the matrix containing the mood scores of every node pair. See `calculate_mood_score` method for how a mood score is calculated between two nodes. Args: nodes: The list of nodes with their features. Returns: The edge score matrix. ''' edge_score_matrix = np . zeros (( len ( nodes ), len ( nodes ))) for n in range ( edge_score_matrix . shape [ 0 ]): for m in range ( edge_score_matrix . shape [ 1 ]): edge_score_matrix [ n ][ m ] = calculate_mood_score ( dict ( age = nodes [ n ][ 0 ], country = nodes [ n ][ 1 ], drinker = nodes [ n ][ 2 ], relationship = nodes [ n ][ 3 ] ), dict ( age = nodes [ m ][ 0 ], country = nodes [ m ][ 1 ], drinker = nodes [ m ][ 2 ], relationship = nodes [ m ][ 3 ] ) ) return edge_score_matrix calculate_mood_score ( edge_1 , edge_2 ) Calculates the mood score between two nodes according to it's features. The mood score is a sum of the individual scores for each feature: Age score (see method calculate_age_score ). Country score (see method edge_score_country ). Drinker score (see method edge_score_drinker ). Relationship score (see method edge_score_relationship ). Parameters: Name Type Description Default edge_1 Features of first node. required edge_2 Features of second node. required Returns: Type Description The mood score. Source code in backend/graphs/evaluation/evaluation.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def calculate_mood_score ( edge_1 , edge_2 ): ''' Calculates the mood score between two nodes according to it's features. The mood score is a sum of the individual scores for each feature: - Age score (see method `calculate_age_score`). - Country score (see method `edge_score_country`). - Drinker score (see method `edge_score_drinker`). - Relationship score (see method `edge_score_relationship`). Args: edge_1: Features of first node. edge_2: Features of second node. Returns: The mood score. ''' edge_score_age = calculate_age_score ( edge_1 [ \"age\" ], edge_2 [ \"age\" ]) edge_score_country = calculate_country_score ( edge_1 [ \"country\" ], edge_2 [ \"country\" ]) edge_score_drinker = calculate_drinker_score ( edge_1 [ \"drinker\" ], edge_2 [ \"drinker\" ]) edge_score_relationship = calculate_relationship_score ( edge_1 [ \"relationship\" ], edge_2 [ \"relationship\" ]) return np . sum ([ edge_score_age , edge_score_country , edge_score_drinker , edge_score_relationship ]) calculate_relationship_score ( relationship_1 , relationship_2 ) Calculates the relationship score of the edge. The relationship score is calculated as followed: if relationship value is the same, score is 0.5 else, score is 0 Parameters: Name Type Description Default relationship_1 int relationship value of node 1. required relationship_2 int relationship value of node 2. required Returns: Type Description float The relationship score. Source code in backend/graphs/evaluation/evaluation.py 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def calculate_relationship_score ( relationship_1 : int , relationship_2 : int ) -> float : ''' Calculates the relationship score of the edge. The relationship score is calculated as followed: - if relationship value is the same, score is 0.5 - else, score is 0 Args: relationship_1 (int): relationship value of node 1. relationship_2 (int): relationship value of node 2. Returns: The relationship score. ''' return 0.5 if relationship_1 == relationship_2 else 0.0 valid_table_graph ( graph ) Checks wheter the graph has a valid seating plan graph structure. Parameters: Name Type Description Default graph nx . Graph The graph to check. required Returns: Type Description True if valid. False if invalid. Source code in backend/graphs/evaluation/evaluation.py 5 6 7 8 9 10 11 12 13 14 15 def valid_table_graph ( graph : nx . Graph ): ''' Checks wheter the graph has a valid seating plan graph structure. Args: graph: The graph to check. Returns: True if valid. False if invalid. ''' return nx . is_isomorphic ( graph , nx . grid_graph (( 2 , graph . number_of_nodes () // 2 )))","title":"Evaluation"},{"location":"graphs/evaluation/evaluation/#backend.graphs.evaluation.evaluation.calculate_age_score","text":"Calculates the age score of the edge. The age score is calculated as followed: if age group difference is 0, score is 1 if age group difference is 1, score is 0.5 if age group difference is 2 or more, score is 0 Parameters: Name Type Description Default age_1 int Age group value of node 1. required age_2 int Age group value of node 2. required Returns: Type Description float The age score. Source code in backend/graphs/evaluation/evaluation.py 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 def calculate_age_score ( age_1 : int , age_2 : int ) -> float : ''' Calculates the age score of the edge. The age score is calculated as followed: - if age group difference is 0, score is 1 - if age group difference is 1, score is 0.5 - if age group difference is 2 or more, score is 0 Args: age_1 (int): Age group value of node 1. age_2 (int): Age group value of node 2. Returns: The age score. ''' difference = abs ( age_1 - age_2 ) if difference == 0 : return 1.0 elif difference == 1 : return 0.5 else : return 0.0","title":"calculate_age_score()"},{"location":"graphs/evaluation/evaluation/#backend.graphs.evaluation.evaluation.calculate_country_score","text":"Calculates the country score of the edge. The country score is calculated as followed: if country is the same, score is 1 if country is different but its language is the same, score is 0.5 if country and its language is different, score is 0 Country codes and language: 0: Germany (german) 1: Swiss (german) 2: Spain (spanish) 3: Mexico (spanish) Parameters: Name Type Description Default country_1 int Country value of node 1. required country_2 int Country value of node 2. required Returns: Type Description float The country score. Source code in backend/graphs/evaluation/evaluation.py 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 def calculate_country_score ( country_1 : int , country_2 : int ) -> float : ''' Calculates the country score of the edge. The country score is calculated as followed: - if country is the same, score is 1 - if country is different but its language is the same, score is 0.5 - if country and its language is different, score is 0 Country codes and language: - 0: Germany (german) - 1: Swiss (german) - 2: Spain (spanish) - 3: Mexico (spanish) Args: country_1 (int): Country value of node 1. country_2 (int): Country value of node 2. Returns: The country score. ''' if country_1 == country_2 : return 1.0 elif ( country_1 ** 2 + country_2 ** 2 ) == ( 0 ** 2 + 1 ** 2 ) or ( country_1 ** 2 + country_2 ** 2 ) == ( 2 ** 2 + 3 ** 2 ): return 0.5 else : return 0.0","title":"calculate_country_score()"},{"location":"graphs/evaluation/evaluation/#backend.graphs.evaluation.evaluation.calculate_drinker_score","text":"Calculates the drinker score of the edge. The drinker score is calculated as followed: if drinker value is the same, score is 1 else, score is 0 Parameters: Name Type Description Default drinker_1 int drinker value of node 1. required drinker_2 int drinker value of node 2. required Returns: Type Description float The drinker score. Source code in backend/graphs/evaluation/evaluation.py 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 def calculate_drinker_score ( drinker_1 : int , drinker_2 : int ) -> float : ''' Calculates the drinker score of the edge. The drinker score is calculated as followed: - if drinker value is the same, score is 1 - else, score is 0 Args: drinker_1 (int): drinker value of node 1. drinker_2 (int): drinker value of node 2. Returns: The drinker score. ''' return 1.0 if drinker_1 == drinker_2 else 0.0","title":"calculate_drinker_score()"},{"location":"graphs/evaluation/evaluation/#backend.graphs.evaluation.evaluation.calculate_edge_score_matrix","text":"Calculates the matrix containing the mood scores of every node pair. See calculate_mood_score method for how a mood score is calculated between two nodes. Parameters: Name Type Description Default nodes The list of nodes with their features. required Returns: Type Description The edge score matrix. Source code in backend/graphs/evaluation/evaluation.py 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 def calculate_edge_score_matrix ( nodes ): ''' Calculates the matrix containing the mood scores of every node pair. See `calculate_mood_score` method for how a mood score is calculated between two nodes. Args: nodes: The list of nodes with their features. Returns: The edge score matrix. ''' edge_score_matrix = np . zeros (( len ( nodes ), len ( nodes ))) for n in range ( edge_score_matrix . shape [ 0 ]): for m in range ( edge_score_matrix . shape [ 1 ]): edge_score_matrix [ n ][ m ] = calculate_mood_score ( dict ( age = nodes [ n ][ 0 ], country = nodes [ n ][ 1 ], drinker = nodes [ n ][ 2 ], relationship = nodes [ n ][ 3 ] ), dict ( age = nodes [ m ][ 0 ], country = nodes [ m ][ 1 ], drinker = nodes [ m ][ 2 ], relationship = nodes [ m ][ 3 ] ) ) return edge_score_matrix","title":"calculate_edge_score_matrix()"},{"location":"graphs/evaluation/evaluation/#backend.graphs.evaluation.evaluation.calculate_mood_score","text":"Calculates the mood score between two nodes according to it's features. The mood score is a sum of the individual scores for each feature: Age score (see method calculate_age_score ). Country score (see method edge_score_country ). Drinker score (see method edge_score_drinker ). Relationship score (see method edge_score_relationship ). Parameters: Name Type Description Default edge_1 Features of first node. required edge_2 Features of second node. required Returns: Type Description The mood score. Source code in backend/graphs/evaluation/evaluation.py 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 def calculate_mood_score ( edge_1 , edge_2 ): ''' Calculates the mood score between two nodes according to it's features. The mood score is a sum of the individual scores for each feature: - Age score (see method `calculate_age_score`). - Country score (see method `edge_score_country`). - Drinker score (see method `edge_score_drinker`). - Relationship score (see method `edge_score_relationship`). Args: edge_1: Features of first node. edge_2: Features of second node. Returns: The mood score. ''' edge_score_age = calculate_age_score ( edge_1 [ \"age\" ], edge_2 [ \"age\" ]) edge_score_country = calculate_country_score ( edge_1 [ \"country\" ], edge_2 [ \"country\" ]) edge_score_drinker = calculate_drinker_score ( edge_1 [ \"drinker\" ], edge_2 [ \"drinker\" ]) edge_score_relationship = calculate_relationship_score ( edge_1 [ \"relationship\" ], edge_2 [ \"relationship\" ]) return np . sum ([ edge_score_age , edge_score_country , edge_score_drinker , edge_score_relationship ])","title":"calculate_mood_score()"},{"location":"graphs/evaluation/evaluation/#backend.graphs.evaluation.evaluation.calculate_relationship_score","text":"Calculates the relationship score of the edge. The relationship score is calculated as followed: if relationship value is the same, score is 0.5 else, score is 0 Parameters: Name Type Description Default relationship_1 int relationship value of node 1. required relationship_2 int relationship value of node 2. required Returns: Type Description float The relationship score. Source code in backend/graphs/evaluation/evaluation.py 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 def calculate_relationship_score ( relationship_1 : int , relationship_2 : int ) -> float : ''' Calculates the relationship score of the edge. The relationship score is calculated as followed: - if relationship value is the same, score is 0.5 - else, score is 0 Args: relationship_1 (int): relationship value of node 1. relationship_2 (int): relationship value of node 2. Returns: The relationship score. ''' return 0.5 if relationship_1 == relationship_2 else 0.0","title":"calculate_relationship_score()"},{"location":"graphs/evaluation/evaluation/#backend.graphs.evaluation.evaluation.valid_table_graph","text":"Checks wheter the graph has a valid seating plan graph structure. Parameters: Name Type Description Default graph nx . Graph The graph to check. required Returns: Type Description True if valid. False if invalid. Source code in backend/graphs/evaluation/evaluation.py 5 6 7 8 9 10 11 12 13 14 15 def valid_table_graph ( graph : nx . Graph ): ''' Checks wheter the graph has a valid seating plan graph structure. Args: graph: The graph to check. Returns: True if valid. False if invalid. ''' return nx . is_isomorphic ( graph , nx . grid_graph (( 2 , graph . number_of_nodes () // 2 )))","title":"valid_table_graph()"},{"location":"graphs/policy/feature_extractor/","text":"GCNFeaturesExtractor Bases: BaseFeaturesExtractor :param observation_space: (gym.spaces.Dict) :param features_dim: (int) Number of features extracted. This corresponds to the number of unit for the last layer. Source code in backend/graphs/policy/feature_extractor.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 class GCNFeaturesExtractor ( BaseFeaturesExtractor ): \"\"\" :param observation_space: (gym.spaces.Dict) :param features_dim: (int) Number of features extracted. This corresponds to the number of unit for the last layer. \"\"\" def __init__ ( self , observation_space : gym . spaces . Dict , features_dim : int = config [ 'model' ][ 'emb_size' ]): super ( GCNFeaturesExtractor , self ) . __init__ ( observation_space , features_dim ) self . config = config self . emb_layer = nn . Linear ( observation_space [ 'node' ] . shape [ 2 ], self . config [ 'model' ][ 'emb_size' ], bias = False ) shared_weights = th . empty ([ 1 , observation_space [ 'adj' ] . shape [ 1 ], self . config [ 'model' ][ 'emb_size' ], self . config [ 'model' ][ 'emb_size' ]]) # TODO: is this right? # shared_weights = th.empty([1, observation_space['adj'].shape[1], observation_space['node'].shape[-1], self.config['model']['emb_size']]) nn . init . xavier_uniform_ ( shared_weights ) self . GCN_layer_shared_weights = nn . Parameter ( shared_weights ) def forward ( self , observations ) -> th . Tensor : # compute node embeddings with GCN (eq 2) emb_node = self . emb_layer ( observations [ 'node' ]) emb_node = GCN_layer ( self , observations [ 'adj' ], emb_node ) for i in range ( self . config [ 'model' ][ 'layer_num_g' ] - 2 ): emb_node = GCN_layer ( self , observations [ 'adj' ], emb_node ) emb_node = GCN_layer ( self , observations [ 'adj' ], emb_node , is_act = False ) emb_node = th . squeeze ( emb_node , axis = 1 ) if self . config [ 'debugging' ][ 'print_extracted_features' ]: print ( emb_node ) return emb_node","title":"Feature extractor"},{"location":"graphs/policy/feature_extractor/#backend.graphs.policy.feature_extractor.GCNFeaturesExtractor","text":"Bases: BaseFeaturesExtractor :param observation_space: (gym.spaces.Dict) :param features_dim: (int) Number of features extracted. This corresponds to the number of unit for the last layer. Source code in backend/graphs/policy/feature_extractor.py 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 class GCNFeaturesExtractor ( BaseFeaturesExtractor ): \"\"\" :param observation_space: (gym.spaces.Dict) :param features_dim: (int) Number of features extracted. This corresponds to the number of unit for the last layer. \"\"\" def __init__ ( self , observation_space : gym . spaces . Dict , features_dim : int = config [ 'model' ][ 'emb_size' ]): super ( GCNFeaturesExtractor , self ) . __init__ ( observation_space , features_dim ) self . config = config self . emb_layer = nn . Linear ( observation_space [ 'node' ] . shape [ 2 ], self . config [ 'model' ][ 'emb_size' ], bias = False ) shared_weights = th . empty ([ 1 , observation_space [ 'adj' ] . shape [ 1 ], self . config [ 'model' ][ 'emb_size' ], self . config [ 'model' ][ 'emb_size' ]]) # TODO: is this right? # shared_weights = th.empty([1, observation_space['adj'].shape[1], observation_space['node'].shape[-1], self.config['model']['emb_size']]) nn . init . xavier_uniform_ ( shared_weights ) self . GCN_layer_shared_weights = nn . Parameter ( shared_weights ) def forward ( self , observations ) -> th . Tensor : # compute node embeddings with GCN (eq 2) emb_node = self . emb_layer ( observations [ 'node' ]) emb_node = GCN_layer ( self , observations [ 'adj' ], emb_node ) for i in range ( self . config [ 'model' ][ 'layer_num_g' ] - 2 ): emb_node = GCN_layer ( self , observations [ 'adj' ], emb_node ) emb_node = GCN_layer ( self , observations [ 'adj' ], emb_node , is_act = False ) emb_node = th . squeeze ( emb_node , axis = 1 ) if self . config [ 'debugging' ][ 'print_extracted_features' ]: print ( emb_node ) return emb_node","title":"GCNFeaturesExtractor"},{"location":"graphs/policy/policy_network/","text":"CustomNetwork Bases: nn . Module Custom network for policy and value function. It receives as input the features extracted by the feature extractor. :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN) :param last_layer_dim_pi: (int) number of units for the last layer of the policy network :param last_layer_dim_vf: (int) number of units for the last layer of the value network Source code in backend/graphs/policy/policy_network.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 class CustomNetwork ( nn . Module ): \"\"\" Custom network for policy and value function. It receives as input the features extracted by the feature extractor. :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN) :param last_layer_dim_pi: (int) number of units for the last layer of the policy network :param last_layer_dim_vf: (int) number of units for the last layer of the value network \"\"\" def __init__ ( self , feature_dim : int , last_layer_dim_pi : int = config [ 'data' ][ 'num_nodes' ] * 2 , last_layer_dim_vf : int = 32 , ): super ( CustomNetwork , self ) . __init__ () self . config = config # IMPORTANT: # Save output dimensions, used to create the distributions self . latent_dim_pi = last_layer_dim_pi self . latent_dim_vf = last_layer_dim_vf # Policy network (GCPN eq 4) self . a_f_mlp = nn . Sequential ( nn . Linear ( feature_dim , feature_dim ), nn . ReLU (), nn . Linear ( feature_dim , 1 ), nn . Flatten (), nn . Softmax ( dim = 1 ), ) self . a_s_mlp = nn . Sequential ( nn . Linear ( feature_dim + 1 , feature_dim ), nn . ReLU (), nn . Linear ( feature_dim , 1 ), nn . Flatten (), nn . Softmax ( dim = 1 ), ) # Value network # TODO: is value network where the discriminator (\"expert\"?) should be used? self . value_net = nn . Sequential ( nn . Linear ( feature_dim , last_layer_dim_vf ), nn . ReLU () ) def forward ( self , features : th . Tensor ) -> Tuple [ th . Tensor , th . Tensor ]: \"\"\" :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network. If all layers are shared, then ``latent_policy == latent_value`` \"\"\" return self . forward_actor ( features ), self . forward_critic ( features ) def forward_actor ( self , features : th . Tensor ) -> th . Tensor : a_f_dist = self . a_f_mlp ( features ) a_f = th . multinomial ( a_f_dist , 1 ) a_f_dist = th . where ( th . tile ( a_f , ( 1 , a_f_dist . shape [ 1 ])) == th . tile ( th . arange ( 0 , a_f_dist . shape [ 1 ]), ( a_f_dist . shape [ 0 ], 1 )), th . ones_like ( a_f_dist ), th . zeros_like ( a_f_dist )) a_f_repeated = th . tile ( th . reshape ( a_f , ( a_f . shape [ 0 ], 1 , 1 )), ( 1 , features . shape [ 1 ], 1 )) emb_cat_s = th . cat (( a_f_repeated , features ), axis = 2 ) a_s_dist = self . a_s_mlp ( emb_cat_s ) # a_s_dist = th.where(th.tile(a_f, (1, a_s_dist.shape[1])) == th.tile(th.arange(0, a_s_dist.shape[1]), ( # a_s_dist.shape[0], 1)), th.zeros_like(a_s_dist), a_s_dist) # make sure that first node is not picked as second node a_s = th . multinomial ( a_s_dist , 1 ) a_s_dist = th . where ( th . tile ( a_s , ( 1 , a_s_dist . shape [ 1 ])) == th . tile ( th . arange ( 0 , a_s_dist . shape [ 1 ]), ( a_s_dist . shape [ 0 ], 1 )), th . ones_like ( a_s_dist ), th . zeros_like ( a_s_dist )) a = th . cat (( a_f_dist , a_s_dist ), dim = 1 ) return a def forward_critic ( self , features : th . Tensor ) -> th . Tensor : v = self . value_net ( features ) v = th . sum ( v , axis = 1 ) return v forward ( features ) :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network. If all layers are shared, then latent_policy == latent_value Source code in backend/graphs/policy/policy_network.py 60 61 62 63 64 65 def forward ( self , features : th . Tensor ) -> Tuple [ th . Tensor , th . Tensor ]: \"\"\" :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network. If all layers are shared, then ``latent_policy == latent_value`` \"\"\" return self . forward_actor ( features ), self . forward_critic ( features )","title":"Policy network"},{"location":"graphs/policy/policy_network/#backend.graphs.policy.policy_network.CustomNetwork","text":"Bases: nn . Module Custom network for policy and value function. It receives as input the features extracted by the feature extractor. :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN) :param last_layer_dim_pi: (int) number of units for the last layer of the policy network :param last_layer_dim_vf: (int) number of units for the last layer of the value network Source code in backend/graphs/policy/policy_network.py 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 class CustomNetwork ( nn . Module ): \"\"\" Custom network for policy and value function. It receives as input the features extracted by the feature extractor. :param feature_dim: dimension of the features extracted with the features_extractor (e.g. features from a CNN) :param last_layer_dim_pi: (int) number of units for the last layer of the policy network :param last_layer_dim_vf: (int) number of units for the last layer of the value network \"\"\" def __init__ ( self , feature_dim : int , last_layer_dim_pi : int = config [ 'data' ][ 'num_nodes' ] * 2 , last_layer_dim_vf : int = 32 , ): super ( CustomNetwork , self ) . __init__ () self . config = config # IMPORTANT: # Save output dimensions, used to create the distributions self . latent_dim_pi = last_layer_dim_pi self . latent_dim_vf = last_layer_dim_vf # Policy network (GCPN eq 4) self . a_f_mlp = nn . Sequential ( nn . Linear ( feature_dim , feature_dim ), nn . ReLU (), nn . Linear ( feature_dim , 1 ), nn . Flatten (), nn . Softmax ( dim = 1 ), ) self . a_s_mlp = nn . Sequential ( nn . Linear ( feature_dim + 1 , feature_dim ), nn . ReLU (), nn . Linear ( feature_dim , 1 ), nn . Flatten (), nn . Softmax ( dim = 1 ), ) # Value network # TODO: is value network where the discriminator (\"expert\"?) should be used? self . value_net = nn . Sequential ( nn . Linear ( feature_dim , last_layer_dim_vf ), nn . ReLU () ) def forward ( self , features : th . Tensor ) -> Tuple [ th . Tensor , th . Tensor ]: \"\"\" :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network. If all layers are shared, then ``latent_policy == latent_value`` \"\"\" return self . forward_actor ( features ), self . forward_critic ( features ) def forward_actor ( self , features : th . Tensor ) -> th . Tensor : a_f_dist = self . a_f_mlp ( features ) a_f = th . multinomial ( a_f_dist , 1 ) a_f_dist = th . where ( th . tile ( a_f , ( 1 , a_f_dist . shape [ 1 ])) == th . tile ( th . arange ( 0 , a_f_dist . shape [ 1 ]), ( a_f_dist . shape [ 0 ], 1 )), th . ones_like ( a_f_dist ), th . zeros_like ( a_f_dist )) a_f_repeated = th . tile ( th . reshape ( a_f , ( a_f . shape [ 0 ], 1 , 1 )), ( 1 , features . shape [ 1 ], 1 )) emb_cat_s = th . cat (( a_f_repeated , features ), axis = 2 ) a_s_dist = self . a_s_mlp ( emb_cat_s ) # a_s_dist = th.where(th.tile(a_f, (1, a_s_dist.shape[1])) == th.tile(th.arange(0, a_s_dist.shape[1]), ( # a_s_dist.shape[0], 1)), th.zeros_like(a_s_dist), a_s_dist) # make sure that first node is not picked as second node a_s = th . multinomial ( a_s_dist , 1 ) a_s_dist = th . where ( th . tile ( a_s , ( 1 , a_s_dist . shape [ 1 ])) == th . tile ( th . arange ( 0 , a_s_dist . shape [ 1 ]), ( a_s_dist . shape [ 0 ], 1 )), th . ones_like ( a_s_dist ), th . zeros_like ( a_s_dist )) a = th . cat (( a_f_dist , a_s_dist ), dim = 1 ) return a def forward_critic ( self , features : th . Tensor ) -> th . Tensor : v = self . value_net ( features ) v = th . sum ( v , axis = 1 ) return v","title":"CustomNetwork"},{"location":"graphs/policy/policy_network/#backend.graphs.policy.policy_network.CustomNetwork.forward","text":":return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network. If all layers are shared, then latent_policy == latent_value Source code in backend/graphs/policy/policy_network.py 60 61 62 63 64 65 def forward ( self , features : th . Tensor ) -> Tuple [ th . Tensor , th . Tensor ]: \"\"\" :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network. If all layers are shared, then ``latent_policy == latent_value`` \"\"\" return self . forward_actor ( features ), self . forward_critic ( features )","title":"forward()"},{"location":"graphs/routers/complete_graph/","text":"get_completed_graph ( edge_string ) Completes the graph with nodes: 0 - Michel 1 - Elias 2 - Sofia 3 - Jorge 4 - Juan 5 - Manuel 6 - Laura 7 - Stefan 8 - Robin 9 - Daniel and edges given via edge_string parameter. The edge_string parameter should come in the format used in the following examples: /complete-graph/0-1_1-2_8-9 (translates into array of 3 edges [(0, 1), (1, 2), (8, 9)] ) /complete-graph/- (translates into empty array of 0 edges [] ) Source code in backend/graphs/routers/complete_graph.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 @router . get ( \"/complete-graph/ {edge_string} \" , tags = [ \"complete_graph\" ]) def get_completed_graph ( edge_string : str ): ''' Completes the graph with nodes: - 0 - Michel - 1 - Elias - 2 - Sofia - 3 - Jorge - 4 - Juan - 5 - Manuel - 6 - Laura - 7 - Stefan - 8 - Robin - 9 - Daniel and edges given via edge_string parameter. The edge_string parameter should come in the format used in the following examples: - `/complete-graph/0-1_1-2_8-9` (translates into array of 3 edges `[(0, 1), (1, 2), (8, 9)]`) - `/complete-graph/-` (translates into empty array of 0 edges `[]`) ''' if edge_string == \"-\" : edges = [] else : edges = [ edge for edge in edge_string . split ( \"_\" )] edges = [( int ( edge . split ( \"-\" )[ 0 ]), int ( edge . split ( \"-\" )[ 1 ])) for edge in edges ] # use nodes from base_graph input_graph = base_graph # add given edges to achieve graph from interface input_graph . add_edges_from ( edges ) # generate completed graph, sorted by descending mood scores completed_graphs = complete_graph ( input_graph , \"2022-06-28_09-50-50\" , run_for_min_seconds = 5 , run_for_max_seconds = 120 ) if completed_graphs : best_graph = completed_graphs [ 1 ] mood_score = completed_graphs [ 0 ] response = { \"status\" : \"success\" , \"completed_graph_edge_list\" : list ( best_graph . edges ), \"completed_graph_mood_score\" : mood_score , } draw_graph ( best_graph ) else : response = { \"status\" : \"failure\" , \"completed_graph_edge_list\" : [], \"completed_graph_mood_score\" : 0 , } return response","title":"Complete graph"},{"location":"graphs/routers/complete_graph/#backend.graphs.routers.complete_graph.get_completed_graph","text":"Completes the graph with nodes: 0 - Michel 1 - Elias 2 - Sofia 3 - Jorge 4 - Juan 5 - Manuel 6 - Laura 7 - Stefan 8 - Robin 9 - Daniel and edges given via edge_string parameter. The edge_string parameter should come in the format used in the following examples: /complete-graph/0-1_1-2_8-9 (translates into array of 3 edges [(0, 1), (1, 2), (8, 9)] ) /complete-graph/- (translates into empty array of 0 edges [] ) Source code in backend/graphs/routers/complete_graph.py 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 @router . get ( \"/complete-graph/ {edge_string} \" , tags = [ \"complete_graph\" ]) def get_completed_graph ( edge_string : str ): ''' Completes the graph with nodes: - 0 - Michel - 1 - Elias - 2 - Sofia - 3 - Jorge - 4 - Juan - 5 - Manuel - 6 - Laura - 7 - Stefan - 8 - Robin - 9 - Daniel and edges given via edge_string parameter. The edge_string parameter should come in the format used in the following examples: - `/complete-graph/0-1_1-2_8-9` (translates into array of 3 edges `[(0, 1), (1, 2), (8, 9)]`) - `/complete-graph/-` (translates into empty array of 0 edges `[]`) ''' if edge_string == \"-\" : edges = [] else : edges = [ edge for edge in edge_string . split ( \"_\" )] edges = [( int ( edge . split ( \"-\" )[ 0 ]), int ( edge . split ( \"-\" )[ 1 ])) for edge in edges ] # use nodes from base_graph input_graph = base_graph # add given edges to achieve graph from interface input_graph . add_edges_from ( edges ) # generate completed graph, sorted by descending mood scores completed_graphs = complete_graph ( input_graph , \"2022-06-28_09-50-50\" , run_for_min_seconds = 5 , run_for_max_seconds = 120 ) if completed_graphs : best_graph = completed_graphs [ 1 ] mood_score = completed_graphs [ 0 ] response = { \"status\" : \"success\" , \"completed_graph_edge_list\" : list ( best_graph . edges ), \"completed_graph_mood_score\" : mood_score , } draw_graph ( best_graph ) else : response = { \"status\" : \"failure\" , \"completed_graph_edge_list\" : [], \"completed_graph_mood_score\" : 0 , } return response","title":"get_completed_graph()"},{"location":"graphs/utils/colors/","text":"Colors defined for graph edges according to their mood scores: 0.0: #f1464c 0.5: #f1464c 1.0: #ffb56b 1.5: #ffb56b 2.0: #d7dd3c 2.5: #d7dd3c 3.0: #60d394 3.5: #60d394","title":"Colors"}]}